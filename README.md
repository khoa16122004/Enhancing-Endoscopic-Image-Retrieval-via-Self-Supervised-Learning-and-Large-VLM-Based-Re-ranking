# Enhancing Endoscopic Image Retrieval via Self-Supervised Learning and Large VLM-Based Re-ranking

![Challenge](https://img.shields.io/badge/ENTRep%20Challenge-Track%203-blue)
![Ranking](https://img.shields.io/badge/Ranking-Top%202-yellow)
![Conference](https://img.shields.io/badge/ACM%20MM%202025-Grand%20Challenge-red)

This repository contains the implementation of our project and research method for **Endoscopic Image Retrieval**, focusing on improving retrieval performance in the challenging medical imaging domain.  

üìå **Team ELO** ‚Äî proudly representing **ELO Lab**.

## Overview
Our work aims to:
- Enhance understanding and analysis of endoscopic images for retrieval tasks.
- Explore the capabilities of **Large Vision-Language Models (VLMs)** in understanding endoscopic images and re-ranking retrieval results.
- Combine **self-supervised learning** with **VLM-based re-ranking** to enhance the performance of Endoscopic Image Retrieval.


## Achievements
üèÜ **ENTRep Challenge @ ACM Multimedia 2025**
- **Top-2** in **Track 3** (Image-to-Text Retrieval)  
- **Top-5** in **Track 2** (Image-to-Image Retrieval)  

## Official Academic Page
For a deeper understanding of our work, please refer to our academic page: _[Coming Soon]_  

## Code Repositories
- **Track 2 (Image-to-Image Retrieval):** [https://github.com/voicon324/ENTChallenge](https://github.com/voicon324/ENTChallenge)  
- **Track 3: (Text-to-Image Retrieval** [https://github.com/Ly-Lynn/Track-3-ENTRep-Challenge](https://github.com/Ly-Lynn/Track-3-ENTRep-Challenge)  

---

## Citation
If you find our work useful, please cite:
```bibtex
@inproceedings{entrep-khoatran2025,
  title={Enhancing Endoscopic Image Retrieval via Self-Supervised Learning and Large VLM-Based Re-ranking},
  author={Khoa Tran, Linh Ly, Duy Khanh Ho, Ngoc Hoang Luong},
  year={2025}
}
